{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In class exercise...\n",
    "* MI is biased in that small sample sizes lead to inaccurate estimates of PDFs, and that can sometimes lead to negative MI values (which should never happen in theory). \n",
    "* A common, and simple, approach, is to compute MI with shuffled condition labels (like randomization tests that we did many weeks back) and then subtract the shuffled MI from the actual MI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import sys\n",
    "epsilon = sys.float_info.epsilon\n",
    "# also define the default font we'll use for figures. \n",
    "fig_font = {'fontname':'Arial', 'size':'20'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First set up two arrays of data (integers)...make them correlated to some degree so that there is a reasonably high MI..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "means = [25,30]\n",
    "std = 10\n",
    "corr = 0.8 # correlation\n",
    "covs = [[std**2,std*std*corr],[std*std*corr,std**2]] \n",
    "N = 50\n",
    "m = np.random.multivariate_normal(means, covs, N).T\n",
    "\n",
    "x = m[0]\n",
    "y = m[1]\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then compute the MI between the arrays. Can do two discrete arrays for simplicity, and import the entropy and conditional entropy functions from the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(x):\n",
    "    \"\"\"compute entropy of discrete array x\n",
    "\n",
    "    Args:\n",
    "        x (int): array of discrete values\n",
    "\n",
    "    Returns:\n",
    "        Hx (float): entropy of x\n",
    "\n",
    "    \"\"\"\n",
    "    # figure out unique values of x - can be more than just 0s, 1s\n",
    "    uniquex = np.unique(x)\n",
    "\n",
    "    Hx = 0\n",
    "    for i in np.arange(len(uniquex)):\n",
    "        # probability that x==uniquex[i]\n",
    "        px = np.sum(x==uniquex[i])/len(x)    \n",
    "\n",
    "        # check for px==0 because log2(0) = -inf\n",
    "        if px!=0:\n",
    "            Hx += (-np.sum( px * np.log2(px+epsilon) ))  \n",
    "        else:\n",
    "            print('px is zero for value ', i)\n",
    "        \n",
    "    return Hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def condEntropy(x,y):\n",
    "    \n",
    "    \"\"\"\n",
    "    conditional entropy, or the average entropy of x given each y, or Hxy\n",
    "    1) For all Y {i=1:numel(X)}, compute the entropy of X given each Y\n",
    "    2) Multiply H(X|Y==i) with the probability of each Y (i.e. pxi)\n",
    "    3) Sum over all i\n",
    "\n",
    "    Args:\n",
    "        x (int): array of discrete values\n",
    "        y (int): array of discrete values\n",
    "        \n",
    "    Returns:\n",
    "        Hxy (float): average conditional entropy of x given y\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Hxy=0\n",
    "    uniquex = np.unique(x)\n",
    "    uniquey = np.unique(y)\n",
    "\n",
    "    # loop over unique elements of y\n",
    "    for i in np.arange(len(uniquey)): \n",
    "\n",
    "        # probability that y==y(i) (prob of each y)\n",
    "        py = np.sum(y==uniquey[i]) / N\n",
    "\n",
    "        # then loop over all possible x's to compute entropy of x at each y\n",
    "        tmp=0\n",
    "        for j in np.arange(len(uniquex)):\n",
    "            px_y = np.sum((x==uniquex[j]) & (y==uniquey[i])) / np.sum(y==uniquey[i])    # e.g. prob x==1 when y==0\n",
    "            tmp += (-( px_y * np.log2(px_y+epsilon) ))                                     # entropy      \n",
    "\n",
    "        # then tally up entropy of x given each specific y multiplied by the probability of that y (py)\n",
    "        Hxy += py*tmp\n",
    "\n",
    "    return Hxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_entropy(p): \n",
    "    # for binary values, entropy can be derived directly from the mean\n",
    "    ent = -(p*np.log2(p+epsilon)+(1-p)*np.log2(1-p+epsilon)) \n",
    "    ent[np.isnan(ent)]=0\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI is:  9.96578428466\n"
     ]
    }
   ],
   "source": [
    "Hx = entropy(x=x)\n",
    "Hxy = condEntropy(x=x,y=y)\n",
    "print('MI is: ', Hx-Hxy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now repeat the above operations, but shuffle the data arrays and repeat the analysis many times (~500-1000 times). Plot the distribution of MI values that you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.0745002068\n",
      "32.6424789184\n",
      "24.4995701577\n",
      "31.9800455017\n",
      "29.4027368503\n",
      "19.3973264829\n",
      "16.6454319145\n",
      "39.6579168229\n",
      "33.0216453599\n",
      "7.17312823953\n"
     ]
    }
   ],
   "source": [
    "rep = 10\n",
    "Hx_rand = np.zeros(rep)\n",
    "Hxy_rand = np.zeros(rep)\n",
    "x_rand = x.copy()\n",
    "y_rand = y.copy()\n",
    "for i in range(rep):\n",
    "    np.random.shuffle(x_rand)\n",
    "    print(x_rand[0])\n",
    "    Hx_rand[i] = entropy(x=x_rand)\n",
    "    Hxy_rand[i] = condEntropy(x=x_rand,y=y_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.20342650e-16,  -3.20342650e-16,  -3.20342650e-16,\n",
       "        -3.20342650e-16,  -3.20342650e-16,  -3.20342650e-16,\n",
       "        -3.20342650e-16,  -3.20342650e-16,  -3.20342650e-16,\n",
       "        -3.20342650e-16])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(Hx_rand-Hxy_rand)\n",
    "Hxy_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now subtract the mean of the shuffled MI values from your 'real' MI value...this will help correct for any bias that is introduced by a limited sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hx-Hxy-(np.mean(Hx_rand-Hxy_rand))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
